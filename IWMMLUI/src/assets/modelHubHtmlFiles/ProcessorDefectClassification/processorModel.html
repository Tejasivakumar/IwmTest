<div>
    <div class="row">
        <h2>Overview</h2>
        <p class="text-justify">Today`s increased level of automation in manufacturing also demands automation of material quality inspection with little human intervention. The trend is to reach human level accuracy or more in quality inspection with automation. To stay competitive, modern Industrial firms strive to achieve both quantity and quality with automation without compromising one over the other.
            To meet industry standards quality inspectors in manufacturing firms, inspect product quality usually after the product is manufactured, AI can be used to inspect products at various stages of the manufacturing process to ensure they meet quality standards. And also, AI can be used to optimize various manufacturing processes, such as casting and forging, to improve efficiency and reduce costs.
            </p>
    </div>

    <div class="row">
        <div class="col-sm-6">
            <div class="card">
                <div class="card-header">
                    Deep Learning Algorithms
                </div>
                <div class="card-body">
                    <ul class="card-text">
                        <li>EfficientNet</li>
                       
                    </ul>
                </div>
            </div>
        </div>
        <div class="col-sm-6">
            <div class="card">
                <div class="card-header">
                    Framework
                </div>
                <div class="card-body">
                    <ul class="card-text">
                        <li>Tensorflow  </li>
                        <li>Keras  </li>   
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <br>

    <div class="row">
        <h2>Datasets used </h2>
        <!-- <p class="text-danger">
            Credit: - Open Lab on Human-Robot Interaction of Peking University.
        </p> -->
        <div>
            Processor datasets containing 3 types of defects and one good type, photoshoped, a graphics editor published by Adobe Systems. The defects defined in the dataset are Bend_pin, Missing_pin, Short_pins and Good pins. This synthetic Processor dataset contains 564 images with 3 defects and good or normal image. 57 images are used for testing a model.

        </div> 
    </div> <br>
    
    <div class="row">
        <h2>Model Hub</h2>
       <h5> EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h5>
        <p >
            EfficientNet is a family of convolutional neural network architectures that were designed to achieve state-of-the-art performance while being computationally efficient. The EfficientNet architecture was proposed in a 2019 paper by Mingxing Tan and Quoc Le from Google Brain.
           The EfficientNet architecture is based on a compound scaling method that uniformly scales the network width, depth, and resolution with a set of scaling coefficients. This allows the architecture to be optimized for different resource constraints, ranging from mobile devices to high-end servers. The scaling method is based on the observation that increasing one dimension of the network requires a proportional increase in the other dimensions in order to maintain a good balance between the network's representational capacity and computational efficiency.
           EfficientNet consists of several versions, labeled from EfficientNet-B0 to EfficientNet-B8, with increasing computational complexity and performance. EfficientNet-B0 is the smallest and most computationally efficient version, while EfficientNet-B8 is the largest and most powerful version. The architecture of EfficientNet includes multiple layers of convolutional, pooling, and activation functions, as well as a global average pooling layer and a fully connected output layer.
            The EfficientNet architecture has achieved state-of-the-art performance on several image classification benchmarks, while requiring fewer computational resources than competing models. It has also been shown to be effective for other computer vision tasks, such as object detection and semantic segmentation.
           
        </p>
    </div>
    <br>

    <div class="row">
        <h4>Process of Training Image classification Model.</h4>
        <p>The process of training an image classification model typically involves the following steps:
        </p>
        <h4>Data Preparation: </h4>
        <p>
            Collect and prepare the dataset for training. This includes data labeling, data cleaning, data augmentation, and data normalization.
        </p>
        <h4>Model Selection:  </h4>
        <p>
            Choose a suitable pre-trained model or build a custom model architecture based on the problem requirements.        </p>
        <h4>Model Compilation:  </h4>
        <p>
            Define the objective function, optimizer, and evaluation metrics to be used during the training process.
                </p>
        <h4>Model Training:  </h4>
        <p>
            Train the model on the prepared dataset. This involves feeding the data to the model, computing the loss, and updating the model parameters using backpropagation.
                </p>
        <h4>Model Evaluation:  </h4>
        <p>
            Evaluate the model's performance on a validation set. This involves computing metrics such as accuracy, precision, recall, and F1 score.
        </p>
        <h4>Hyperparameter Tuning:   </h4>
        <p>
        Fine-tune the model hyperparameters, such as learning rate, batch size, and number of epochs, to optimize the model performance. 
        </p>
        <h4>Model Deployment:   </h4>
        <p>
            Once the model is trained and evaluated, it can be deployed for inference on new data. This may involve integrating the model into a web application, mobile app, or other production system.
        </p>
        <br>
        <p>Throughout the training process, it is important to monitor the model performance and make adjustments as needed. This may include adjusting the training parameters, modifying the model architecture, or collecting more data. With careful preparation, training, and evaluation, it is possible to develop an accurate image classification model that can be used for a wide range of computer vision tasks.</p>

    </div>
    <div class="row">
        
        <h4>Installing Required Libraries</h4>
        <p> pip install -r C:\Users\Rajesh.Mandal\Downloads\democheck\demoprocessor\requirements.txt</p>
        <h4>Train and hyper-tune the model.</h4>
        <p>model.fit(train_generator, validation_data=validation_generator, epochs=epochs, batch_size=bs,steps_per_epoch=len(train_generator), validation_steps=len(validation_generator))</p>

    </div>


    <div class="row">
        <h4>Training code:</h4>
        <pre>
            <code>
                #load the datasets
                #train and validation data structure--|
                #       | 
                #        --- Good
                #        --- Bend_pins
                #        --- Short_pins
                #        --- Missing_pins
                
                
                
                train = "/content/drive/MyDrive/Processor/images/train/"
                val = "/content/drive/MyDrive/Processor/images/val/"

                from tensorflow.keras.preprocessing.image import ImageDataGenerator

                train_datagen = ImageDataGenerator(
                rescale=1./255,
                shear_range=0.2,
                zoom_range=0.2,
                horizontal_flip=True,
                vertical_flip = True)

                test_datagen = ImageDataGenerator(rescale=1./255)

                train_generator = train_datagen.flow_from_directory(
                train,
                target_size=(224, 224),
                batch_size=32,
                class_mode='categorical')

                print("train_generator: ",train_generator)


                validation_generator = test_datagen.flow_from_directory(
                val,
                target_size=(224, 224),
                batch_size=32,
                class_mode='categorical')

                img_size = (224,224)
                if K.image_data_format() == "channels_first":
                input_shape = (3, img_size[0], img_size[1])
                else:
                input_shape = (img_size[0], img_size[1], 3)
                base = efn.EfficientNetB2(include_top=False, weights="imagenet", input_shape=input_shape) 
                
                Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
                115515392/115515256 [==============================] - 19s 0us/step

                x1 = GlobalAveragePooling2D(name="gap")(base.output)
                x2 = GlobalMaxPooling2D(name="gmp")(base.output)
                x = Concatenate(name="concat")([x1, x2])

                x = Dense(4, kernel_initializer="he_normal", name="classifier")(x)
                x = Activation("softmax", name="softmax")(x)

                model = tf.keras.models.Model(inputs=base.input, outputs=x)

                loss = tf.keras.losses.CategoricalCrossentropy()
                opt = tf.optimizers.Adam(lr=1e-3)
                epochs = 50
                bs = 4

                model.compile(loss=loss, optimizer=opt, metrics=["accuracy"])


                model.fit(train_generator, validation_data=validation_generator, epochs=epochs, batch_size=bs,
                steps_per_epoch=len(train_generator), validation_steps=len(validation_generator))


            </code>
        </pre>

    </div>
    <div class="row">
        <h4>Check the training graph</h4>
        <pre>
            <code>
                import matplotlib.pyplot as plt 
                import seaborn as sns 

                plt.subplots(figsize = (8,4))
                sns.lineplot(data = pd.DataFrame(hist_acc_loss, index = range(1, 1 + len(hist_epoch))))
                plt.title("Training Evaluation", fontweight = "bold", fontsize = 20)
                plt.xlabel("Epochs")
                plt.ylabel("Metrics")
                plt.legend(labels = ['val loss','val accuracy','train loss','train accuracy'])
                plt.show()
            </code>
        </pre>
        <img src="assets/modelHubImageFiles/processorDefect.png" alt="" />

    </div >

    <div class="row">
        <h4>Test The Model</h4>
        <pre>
            <code>
                #load the model
                import glob
                import cv2 

               model = tf.keras.models.load_model("/content/drive/MyDrive/Processor/Model/processoreffB5.h5")
               class_name = ["bend_pin","Good","missing_pins","short_pins"]

               dest_path = "/content/drive/MyDrive/Processor/result/"
               for i in glob.glob("/content/drive/MyDrive/Processor/images/test/*"):
               file_name = i.split('/')[-1]
               img1 = cv2.imread(i)
               img = cv2.resize(img1, (224,224))

               # convert the image to a tensor for inference
               img = np.expand_dims(img, 0).astype(np.float32) / 255.0
               preds = np.squeeze(model.predict(img)[0]) 
               index = np.argmax(preds)
               cls_name =class_name[index]
               cv2.putText(img1, cls_name, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 
               1, (255, 0, 0), 3, cv2.LINE_AA)
               cv2.imwrite(dest_path+file_name,img1)
            </code>
        </pre>
    </div>

    <div class="row">
       <h4>Model Prediction</h4>
       <img src="assets/modelHubImageFiles/MPrediction1.PNG" alt="" />
       <img src="assets/modelHubImageFiles/MPredection2.PNG" alt="" />
       <img src="assets/modelHubImageFiles/MPredection3.PNG" alt="" />
       <img src="assets/modelHubImageFiles/MPredection4.PNG" alt="" />
      
    </div>

</div>